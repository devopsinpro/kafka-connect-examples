# Azure Blog Storage Sink example for Kafka Connect
# This example is meant to
# be accompanied with blog post and screencast
# at https://supergloo.com
# 
# People are counting on you
# 

name=azure-bs-sink
connector.class=io.confluent.connect.azure.blob.AzureBlobStorageSinkConnector
tasks.max=1
flush.size=3

azblob.account.name=tmcgrathstorageaccount
# azblob.account.key=<use-yours-here-or-set-in-env-variable-as-i-do-in-demo>
azblob.container.name=kafka-connect-example

# Key converter same for both examples
key.converter=org.apache.kafka.connect.storage.StringConverter

# Avro example with orders test data
# topics=orders
#format.class=io.confluent.connect.azure.blob.format.avro.AvroFormat
#value.converter=io.confluent.connect.avro.AvroConverter
#value.converter.schema.registry.url=http://localhost:8081

# JSON example with pageviews test data
topics=pageviews
format.class=io.confluent.connect.azure.blob.format.json.JsonFormat
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false

schema.compatibility=NONE

partitioner.class=io.confluent.connect.storage.partitioner.DefaultPartitioner

#############################
# CONFLUENT LICENSE SETTINGS
#############################

confluent.license=
confluent.topic.bootstrap.servers=localhost:9092
confluent.topic.replication.factor=1
